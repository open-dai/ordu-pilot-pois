/*
 *    Geotools2 - OpenSource mapping toolkit
 *    http://geotools.org
 *    (C) 2002-2006, Geotools Project Managment Committee (PMC)
 *
 *    This library is free software; you can redistribute it and/or
 *    modify it under the terms of the GNU Lesser General Public
 *    License as published by the Free Software Foundation;
 *    version 2.1 of the License.
 *
 *    This library is distributed in the hope that it will be useful,
 *    but WITHOUT ANY WARRANTY; without even the implied warranty of
 *    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 *    Lesser General Public License for more details.
 *
 */
package com.sampas.socbs.core.data.arcsde.impl;

import java.io.IOException;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.List;
import java.util.NoSuchElementException;
import java.util.logging.Level;
import java.util.logging.Logger;
import net.sf.jsqlparser.statement.select.PlainSelect;
import org.geotools.data.DataSourceException;
import org.geotools.data.DataUtilities;
import org.geotools.data.DefaultQuery;
import org.geotools.data.Query;
import org.geotools.data.jdbc.FilterToSQLException;
import org.geotools.feature.AttributeType;
import org.geotools.feature.FeatureType;
import org.geotools.feature.SchemaException;
import org.geotools.filter.FilterAttributeExtractor;
import org.geotools.filter.visitor.PostPreProcessFilterSplittingVisitor;
import org.opengis.filter.Filter;
import com.esri.sde.sdk.client.SeException;
import com.esri.sde.sdk.client.SeExtent;
import com.esri.sde.sdk.client.SeFilter;
import com.esri.sde.sdk.client.SeLayer;
import com.esri.sde.sdk.client.SeQuery;
import com.esri.sde.sdk.client.SeQueryInfo;
import com.esri.sde.sdk.client.SeRow;
import com.esri.sde.sdk.client.SeSqlConstruct;
import com.esri.sde.sdk.client.SeTable;
import com.vividsolutions.jts.geom.Envelope;

/**
 * Wrapper class for SeQuery to hold a SeConnection until close() is called and provide utility
 * methods.
 * 
 * @author Gabriel Roldan, Axios Engineering
 * @source $URL:
 *         http://svn.geotools.org/geotools/trunk/gt/modules/plugin/arcsde/datastore/src/main/java/org/geotools/arcsde/data/ArcSDEQuery.java $
 * @version $Id: ArcSDEQuery.java 30166 2008-05-08 09:29:04Z groldan $
 */
@SuppressWarnings("unchecked")
class ArcSDEQuery {
    /** Shared package's logger */
    private static final Logger LOGGER = org.geotools.util.logging.Logging
            .getLogger(ArcSDEQuery.class.getName());

    /**
     * The connection to the ArcSDE server obtained when first created the SeQuery in
     * <code>getSeQuery</code>. It is retained until <code>close()</code> is called. Do not use
     * it directly, but through <code>getConnection()</code>.
     * <p>
     * NOTE: this member is package visible only for unit test pourposes
     * </p>
     */
    final ArcSDEPooledConnection connection;

    /**
     * The exact feature type this query is about to request from the arcsde server. It could have
     * less attributes than the ones of the actual table schema, in which case only those attributes
     * will be requested.
     */
    private FeatureType schema;

    /**
     * The query built using the constraints given by the geotools Query. It must not be accessed
     * directly, but through <code>getSeQuery()</code>, since it is lazyly created
     */
    private SeQuery query;

    /**
     * Holds the geotools Filter that originated this query from which can parse the sql where
     * clause and the set of spatial filters for the ArcSDE Java API
     */
    private ArcSDEQuery.FilterSet filters;

    /** The lazyly calculated result count */
    private int resultCount = -1;

    /** DOCUMENT ME! */
    private FIDReader fidReader;

    private Object[] previousRowValues;

    private ArcSdeVersionHandler versioningHandler;

    /**
     * Creates a new SDEQuery object.
     * 
     * @param connection the connection attached to the life cycle of this query
     * @param schema the schema with all the attributes as expected.
     * @param filterSet DOCUMENT ME!
     * @param versioningHandler used to transparently set up SeQuery streams pointing to the propper
     *            version edit state when appropriate
     * @throws DataSourceException DOCUMENT ME!
     * @see prepareQuery
     */
    private ArcSDEQuery(final ArcSDEPooledConnection connection,
                        final FeatureType schema,
                        final FilterSet filterSet,
                        final FIDReader fidReader,
                        ArcSdeVersionHandler versioningHandler) throws DataSourceException {
        this.connection = connection;
        this.schema = schema;
        this.filters = filterSet;
        this.fidReader = fidReader;
        this.versioningHandler = versioningHandler;
    }

    /**
     * Creates a Query to be executed over a registered ArcSDE layer (whether it is from a table or
     * a spatial view).
     * 
     * @param conn the connection the query works over. As its managed by the calling code its the
     *            calling code responsibility to close it when done.
     * @param fullSchema
     * @param query
     * @param isMultiversioned whether the table is versioned, if so, the default version and
     *            current state will be used for the SeQuery
     * @return
     * @throws IOException
     */
    public static ArcSDEQuery createQuery(final ArcSDEPooledConnection conn,
            final FeatureType fullSchema,
            final Query query,
            final FIDReader fidReader,
            final ArcSdeVersionHandler versioningHandler) throws IOException {

        Filter filter = query.getFilter();

        LOGGER.fine("Creating new ArcSDEQuery");

        final String typeName = fullSchema.getTypeName();
        final SeLayer sdeLayer = conn.getLayer(typeName);
        final FeatureType querySchema = getQuerySchema(query, fullSchema);
        // create the set of filters to work over
        final ArcSDEQuery.FilterSet filters = new ArcSDEQuery.FilterSet(sdeLayer, filter,
                querySchema, null, null, fidReader);

        final ArcSDEQuery sdeQuery;
        sdeQuery = new ArcSDEQuery(conn, querySchema, filters, fidReader, versioningHandler);
        return sdeQuery;
    }

    /**
     * Creates a query to be executed over an inprocess view (a view defined by a SQL SELECT
     * statement at the datastore configuration)
     * 
     * @return the newly created ArcSDEQuery.
     * @throws IOException see <i>throws DataSourceException</i> bellow.
     * @see ArcSDEDataStore#registerView(String, PlainSelect)
     */
    public static ArcSDEQuery createInprocessViewQuery(final ArcSDEPooledConnection conn,
            final FeatureType fullSchema,
            final Query query,
            final SeQueryInfo definitionQuery,
            final PlainSelect viewSelectStatement) throws IOException {

        final Filter filter = query.getFilter();
        final FIDReader fidReader = FIDReader.NULL_READER;
        final SeLayer sdeLayer;

        // the first table has to be the main layer
        final SeSqlConstruct construct;
        try {
            construct = definitionQuery.getConstruct();
        } catch (SeException e) {
            throw new ArcSdeException("shouldn't happen: " + e.getMessage(), e);
        }
        final String[] tables = construct.getTables();
        String layerName = tables[0];
        // @REVISIT: HACK HERE!, look how to get rid of alias in
        // query info, or
        // better stop using queryinfo as definition query and use
        // the PlainSelect,
        // then construct the query info dynamically when needed?
        if (layerName.indexOf(" AS") > 0) {
            layerName = layerName.substring(0, layerName.indexOf(" AS"));
        }
        sdeLayer = conn.getLayer(layerName);

        final FeatureType querySchema = getQuerySchema(query, fullSchema);
        // create the set of filters to work over
        final ArcSDEQuery.FilterSet filters = new ArcSDEQuery.FilterSet(sdeLayer, filter,
                querySchema, definitionQuery, viewSelectStatement, fidReader);

        final ArcSDEQuery sdeQuery;
        sdeQuery = new ArcSDEQuery(conn, querySchema, filters, fidReader,
                ArcSdeVersionHandler.NONVERSIONED_HANDLER);
        return sdeQuery;
    }

    /**
     * Returns a {@link FeatureType} whichs a "view" of the <code>fullSchema</code> adapted
     * as per the required query property names.
     * 
     * @param query the query containing the list of property names required by the output schema
     *            and the {@link Filter query predicate} from which to fetch required properties to
     *            be used at runtime filter evaluation.
     * @param fullSchema a feature type representing an ArcSDE layer full schema.
     * @return a FeatureType derived from <code>fullSchema</code> which contains the property
     *         names required by the <code>query</code> and the ones referenced in the query
     *         filter.
     * @throws DataSourceException
     */
    private static FeatureType getQuerySchema(final Query query,
            final FeatureType fullSchema) throws DataSourceException {
        // guess which properties need to actually be retrieved.
        final List queryColumns = getQueryColumns(query, fullSchema);
        final String[] attNames = (String[]) queryColumns.toArray(new String[queryColumns.size()]);

        try {
            // create the resulting feature type for the real attributes to
            // retrieve
            FeatureType querySchema = DataUtilities.createSubType(fullSchema, attNames);
            return querySchema;
        } catch (SchemaException ex) {
            throw new DataSourceException(
                    "Some requested attributes do not match the table schema: " + ex.getMessage(),
                    ex);
        }
    }

    private static List getQueryColumns(Query query, final FeatureType fullSchema)
            throws DataSourceException {
        final List columnNames = new ArrayList();

        final String[] queryColumns = query.getPropertyNames();

        if ((queryColumns == null) || (queryColumns.length == 0)) {
            final AttributeType[] attNames = fullSchema.getAttributeTypes();
            for (int i = 0; i < attNames.length; i++) {
                AttributeType att = attNames[i];
                String attName = att.getLocalName();
                // de namespace-ify the names
                // REVISIT: this shouldnt be needed!
                if (attName.indexOf(":") != -1) {
                    attName = attName.substring(attName.indexOf(":") + 1);
                }
                columnNames.add(attName);
            }
        } else {
            columnNames.addAll(Arrays.asList(queryColumns));
        }

        // Ok, say we don't support the full filter natively and it references
        // some properties, then they have to be retrieved in order to evaluate
        // the filter at runtime
        Filter f = query.getFilter();
        if (f != null) {
            final FilterAttributeExtractor attExtractor = new FilterAttributeExtractor(fullSchema);
            f.accept(attExtractor, null);
            final String[] filterAtts = attExtractor.getAttributeNames();
            for (int i = 0; i < filterAtts.length; i++) {
                String attName = filterAtts[i];
                if (!columnNames.contains(attName)) {
                    columnNames.add(attName);
                }
            }
        }

        return columnNames;
    }

    /**
     * Returns the FID strategy used
     * 
     * @return DOCUMENT ME!
     */
    public FIDReader getFidReader() {
        return this.fidReader;
    }

    public static ArcSDEQuery.FilterSet createFilters(SeLayer layer,
            FeatureType schema,
            Filter filter,
            SeQueryInfo qInfo,
            PlainSelect viewSelect,
            FIDReader fidReader) throws NoSuchElementException, IOException {

        ArcSDEQuery.FilterSet filters = new ArcSDEQuery.FilterSet(layer, filter, schema, qInfo,
                viewSelect, fidReader);

        return filters;
    }

    /**
     * Returns the stream used to fetch rows, creating it if it was not yet created.
     * 
     * @throws SeException
     * @throws IOException
     */
    private SeQuery getSeQuery() throws IOException {
        if (this.query == null) {
            try {
                String[] propsToQuery = fidReader.getPropertiesToFetch(this.schema);
                this.query = createSeQueryForFetch(propsToQuery);
            } catch (SeException e) {
                throw new ArcSdeException(e);
            } 
        }
        return this.query;
    }

    /**
     * creates an SeQuery with the filters provided to the constructor and returns it. Queries
     * created with this method can be used to execute and fetch results. They cannot be used for
     * other operations, such as calculating layer extents, or result count.
     * <p>
     * Difference with {@link #createSeQueryForFetch(ArcSDEPooledConnection, String[])} is tha this
     * function tells <code>SeQuery.setSpatialConstraints</code> to NOT return geometry based
     * bitmasks, which are needed for calculating the query extent and result count, but not for
     * fetching SeRows.
     * </p>
     * 
     * @param propertyNames names of attributes to build the query for, respecting order
     * @return DOCUMENT ME!
     * @throws SeException if the ArcSDE Java API throws it while creating the SeQuery or setting it
     *             the spatial constraints.
     * @throws IOException DOCUMENT ME!
     */
    private SeQuery createSeQueryForFetch(String[] propertyNames) throws SeException, IOException {
        if (LOGGER.isLoggable(Level.FINEST)) {
            LOGGER.finest("constructing new sql query with connection: " + connection
                    + ", propnames: " + java.util.Arrays.asList(propertyNames)
                    + " sqlConstruct where clause: '" + this.filters.getSeSqlConstruct().getWhere()
                    + "'");
        }

        SeQuery seQuery = new SeQuery(connection);
        setQueryVersionState(seQuery);

        SeQueryInfo qInfo = filters.getQueryInfo(propertyNames);
        if (LOGGER.isLoggable(Level.FINER)) {
            String msg = "ArcSDE query is: " + toString(qInfo);
            LOGGER.finer(msg);
        }
        try {
            seQuery.prepareQueryInfo(qInfo);
        } catch (SeException e) {
            // HACK: a DATABASE LEVEL ERROR (code -51) occurs when using
            // prepareQueryInfo but the geometry att is not required in the list
            // of properties to retrieve, and thus propertyNames contains
            // SHAPE.fid as a last resort to get a fid
            if (-51 == e.getSeError().getSdeError()) {
                seQuery.close();
                seQuery = new SeQuery(connection, propertyNames, filters.getSeSqlConstruct());
                setQueryVersionState(seQuery);
                seQuery.prepareQuery();
            } else {
                throw new ArcSdeException(e);
            }
        }

        SeFilter[] spatialConstraints = this.filters.getSpatialFilters();
        if (spatialConstraints.length > 0) {
            final boolean setReturnGeometryMasks = false;
            seQuery.setSpatialConstraints(SeQuery.SE_OPTIMIZE, setReturnGeometryMasks,
                    spatialConstraints);
        }

        return seQuery;
    }

    private String toString(SeQueryInfo qInfo) {
        StringBuffer sb = new StringBuffer("SeQueryInfo[\n\tcolumns=");
        try {
            SeSqlConstruct sql = qInfo.getConstruct();
            String[] tables = sql.getTables();
            String[] cols = qInfo.getColumns();
            String by = null;
            try {
                by = qInfo.getByClause();
            } catch (NullPointerException npe) {
                // no-op
            }
            String where = sql.getWhere();
            for (int i = 0; cols != null && i < cols.length; i++) {
                sb.append(cols[i]);
                if (i < cols.length - 1)
                    sb.append(", ");
            }
            sb.append("\n\tTables=");
            for (int i = 0; i < tables.length; i++) {
                sb.append(tables[i]);
                if (i < tables.length - 1)
                    sb.append(", ");
            }
            sb.append("\n\tWhere=");
            sb.append(where);
            sb.append("\n\tOrderBy=");
            sb.append(by);
        } catch (SeException e) {
            sb.append("Exception retrieving query info properties: " + e.getMessage());
        }
        sb.append("]");
        return sb.toString();
    }

    /**
     * creates an SeQuery with the filters provided to the constructor and returns it. Queries
     * created with this method are to be used for calculating layer extents and result counts.
     * These queries cannot be executed or used to fetch results.
     * <p>
     * Difference with {@link #createSeQueryForFetch(ArcSDEPooledConnection, String[])} is that this
     * function tells <code>SeQuery.setSpatialConstraints</code> to return geometry based
     * bitmasks, which are needed for calculating the query extent and result count, but not for
     * fetching SeRows.
     * </p>
     * 
     * @param whether to instruct the query to gather "geometry masks". Should be true to calculate
     *            counts and false to calculate bounds, or a DATABASE LEVEL ERROR is thrown by
     *            ArcSDE...
     * @return an SeQuery settled up with the attribute and spatial constraints to calculate result
     *         count and envelope
     * @throws SeException if the ArcSDE Java API throws it while creating the SeQuery or setting it
     *             the spatial constraints.
     * @throws IOException DOCUMENT ME!
     */
    private SeQuery createSeQueryForQueryInfo(final boolean setReturnGeometryMasks)
            throws SeException, IOException {

        SeQuery seQuery = new SeQuery(connection);
        setQueryVersionState(seQuery);
        SeFilter[] spatialConstraints = this.filters.getSpatialFilters();

        if (spatialConstraints.length > 0) {
            seQuery.setSpatialConstraints(SeQuery.SE_OPTIMIZE, setReturnGeometryMasks,
                    spatialConstraints);
        }

        return seQuery;
    }

    /**
     * If the table being queried is multi versioned (we have a flag indicating it), retrieves the
     * default version and its current version state to use for the query object
     * 
     * @param seQuery
     * @throws IOException
     */
    private void setQueryVersionState(SeQuery seQuery) throws IOException {
        versioningHandler.setUpStream(connection, seQuery);
    }

    /**
     * Returns the schema of the originating Query
     * 
     * @return the schema of the originating Query
     */
    public FeatureType getSchema() {
        return this.schema;
    }

    /**
     * DOCUMENT ME!
     * 
     * @return DOCUMENT ME!
     */
    public ArcSDEQuery.FilterSet getFilters() {
        return this.filters;
    }

    /**
     * Convenient method to just calculate the result count of a given query.
     */
    public static int calculateResultCount(final ArcSDEPooledConnection connection,
            final FeatureTypeInfo typeInfo,
            final Query query,
            final ArcSdeVersionHandler versioningHandler) throws IOException {

        ArcSDEQuery countQuery = null;
        final int count;
        try {
            final FeatureType fullSchema = typeInfo.getFeatureType();
            if (typeInfo.isInProcessView()) {
                final SeQueryInfo definitionQuery = typeInfo.getSdeDefinitionQuery();
                final PlainSelect viewSelectStatement = typeInfo.getDefinitionQuery();
                countQuery = createInprocessViewQuery(connection, fullSchema, query,
                        definitionQuery, viewSelectStatement);
            } else {
                final FIDReader fidStrategy = typeInfo.getFidStrategy();
                countQuery = createQuery(connection, fullSchema, query, fidStrategy,
                        versioningHandler);
            }
            count = countQuery.calculateResultCount();
        } finally {
            if (countQuery != null) {
                countQuery.close();
            }
        }
        return count;
    }

    /**
     * Convenient method to just calculate the resulting bound box of a given query.
     */
    public static Envelope calculateQueryExtent(final ArcSDEPooledConnection connection,
            final FeatureTypeInfo typeInfo,
            final Query query,
            final ArcSdeVersionHandler versioningHandler) throws IOException {

        final FeatureType fullSchema = typeInfo.getFeatureType();
        final String defaultGeomAttName = fullSchema.getDefaultGeometry().getLocalName();

        // we're calculating the bounds, so we'd better be sure and add the
        // spatial column to the query's propertynames
        final DefaultQuery realQuery = new DefaultQuery(query);
        realQuery.setPropertyNames(new String[] { defaultGeomAttName });

        final ArcSDEQuery boundsQuery;

        if (typeInfo.isInProcessView()) {
            final SeQueryInfo definitionQuery = typeInfo.getSdeDefinitionQuery();
            final PlainSelect viewSelectStatement = typeInfo.getDefinitionQuery();
            boundsQuery = createInprocessViewQuery(connection, fullSchema, realQuery,
                    definitionQuery, viewSelectStatement);
        } else {
            boundsQuery = createQuery(connection, fullSchema, realQuery, FIDReader.NULL_READER,
                    versioningHandler);
        }

        Envelope queryExtent = null;
        try {
            Filter unsupportedFilter = boundsQuery.getFilters().getUnsupportedFilter();
            if (unsupportedFilter == Filter.INCLUDE) {
                // we can only use an optimized bounds calculation if the
                // query is fully supported by sde
                queryExtent = boundsQuery.calculateQueryExtent();
            }
        } finally {
            boundsQuery.close();
        }
        return queryExtent;
    }

    /**
     * if the query has been parsed as just a where clause filter, or has no filter at all, the
     * result count calculation is optimized by selecting a <code>count()</code> single row. If
     * the filter involves any kind of spatial filter, such as BBOX, the calculation can't be
     * optimized by this way, because the ArcSDE Java API throws a <code>"DATABASE LEVEL
     * ERROR OCURRED"</code>
     * exception. So, in this case, a query over the shape field is made and the result is traversed
     * counting the number of rows inside a while loop
     * 
     * @return DOCUMENT ME!
     * @throws IOException DOCUMENT ME!
     * @throws DataSourceException DOCUMENT ME!
     */
    public int calculateResultCount() throws IOException {
        LOGGER.fine("about to calculate result count");

        if (this.resultCount == -1) {
            String aFieldName = "*";
            String[] columns = { aFieldName };

            SeQuery countQuery = null;

            if (filters.getUnsupportedFilter() == Filter.INCLUDE) {
                // there's nothing to filter post-db, so we're clear to do the
                // result count
                // by sending a query to the db and completely trusting the
                // result.

                try {
                    countQuery = createSeQueryForQueryInfo(true);
                    SeQueryInfo qInfo = filters.getQueryInfo(columns);

                    SeTable.SeTableStats tableStats = countQuery.calculateTableStatistics(
                            aFieldName, SeTable.SeTableStats.SE_COUNT_STATS, qInfo, 0);

                    this.resultCount = tableStats.getCount();
                } catch (SeException e) {
                    if (LOGGER.isLoggable(Level.FINE)) {
                        LOGGER.fine("Error calculating result cout with SQL where clause: "
                                + this.filters.getSeSqlConstruct().getWhere());
                    }
                    // why throw an exception here? Just return -1 and let the
                    // caller deal with it...
                    // throw new DataSourceException("Calculating result count:
                    // " + e.getSeError().getErrDesc(), e);
                } finally {
                    close(countQuery);
                }

            } else {
                // well, we've got to filter the results after the query, so
                // let's not do that twice. -1 is the best anyone will get
                // on this one...
                LOGGER
                        .fine("Non-supported ArcSDE filters included in this query.  Can't pre-calculate result count.");
            }
        }

        return this.resultCount;
    }

    /**
     * Returns the envelope for all features within the layer that pass any SQL construct, state, or
     * spatial constraints for the stream.
     * 
     * @return DOCUMENT ME!
     * @throws IOException DOCUMENT ME!
     * @throws DataSourceException DOCUMENT ME!
     */
    public Envelope calculateQueryExtent() throws IOException {
        Envelope envelope = null;
        SeQuery extentQuery = null;

        LOGGER.fine("Building a new SeQuery to consult it's resulting envelope");

        try {
            SeExtent extent;

            String[] spatialCol = { schema.getDefaultGeometry().getLocalName() };

            extentQuery = createSeQueryForQueryInfo(false);
//            {
//                SeQuery seQuery = new SeQuery(connection);
//                setQueryVersionState(seQuery);
//                SeFilter[] spatialConstraints = this.filters.getSpatialFilters();
//
//                if (spatialConstraints.length > 0) {
//                    final boolean setReturnGeometryMasks = false;
//                    seQuery.setSpatialConstraints(SeQuery.SE_OPTIMIZE, setReturnGeometryMasks,
//                            spatialConstraints);
//                }
//                extentQuery = seQuery;
//            }

            SeQueryInfo sdeQueryInfo = filters.getQueryInfo(spatialCol);
            //
            // {
            // SeQuery spatialQuery = null;
            // SeSqlConstruct sqlCons = new SeSqlConstruct(filters.sdeLayer.getName());
            // sqlCons.setWhere("1=1");
            // spatialQuery = new SeQuery(connection, spatialCol, sqlCons);
            // SeFilter[] spatialFilters = filters.getSpatialFilters();
            // if (spatialFilters.length > 0) {
            // spatialQuery.setSpatialConstraints(SeQuery.SE_OPTIMIZE, true, spatialFilters);
            // }
            // // spatialQuery.execute();
            // extent = spatialQuery.calculateLayerExtent(sdeQueryInfo);
            // }
            //            
            extent = extentQuery.calculateLayerExtent(sdeQueryInfo);

            envelope = new Envelope(extent.getMinX(), extent.getMaxX(), extent.getMinY(), extent
                    .getMaxY());
            LOGGER.fine("got extent: " + extent + ", built envelope: " + envelope);
            // }
        } catch (SeException ex) {
            SeSqlConstruct sqlCons = this.filters.getSeSqlConstruct();
            String sql = (sqlCons == null) ? null : sqlCons.getWhere();
            String tables = (sqlCons == null) ? null : Arrays.asList(sqlCons.getTables())
                    .toString();
            if (ex.getSeError().getSdeError() == -288) {
                // gah, the dreaded 'LOGFILE SYSTEM TABLES DO NOT EXIST' error.
                // this error is worthless. Make it quiet, at least.
                LOGGER.severe("ArcSDE is complaining that your 'LOGFILE SYSTEM "
                        + "TABLES DO NOT EXIST'.  This is an ignorable error.");
            } else {
                ArcSdeException sdeEx = new ArcSdeException(ex);
                LOGGER.log(Level.SEVERE, "***********************\ntables: " + tables
                        + "\nfilter: " + this.filters.getGeometryFilter() + "\nSQL: " + sql, sdeEx);
                throw sdeEx;
            }
        } finally {
            close(extentQuery);
        }

        return envelope;
    }

    /**
     * Silently closes this query.
     * 
     * @param query
     */
    private static void close(SeQuery query) {
        if (query == null) {
            return;
        }

        try {
            query.close();
        } catch (SeException e) {
            LOGGER.warning("Closing query: " + e.getSeError().getErrDesc());
        }
    }

    // //////////////////////////////////////////////////////////////////////
    // //////////// RELEVANT METHODS WRAPPED FROM SeStreamOp ////////////////
    // //////////////////////////////////////////////////////////////////////

    /**
     * Closes the query.
     * <p>
     * The {@link ArcSDEPooledConnection connection} used by the query is not closed by this
     * operation as it was provided by the calling code and thus it is its responsibility to handle
     * the connection life cycle.
     * </p>
     */
    public void close() {
        close(this.query);
        this.query = null;
    }

    /**
     * Tells the server to execute a stream operation.
     * 
     * @throws IOException DOCUMENT ME!
     * @throws DataSourceException DOCUMENT ME!
     */
    public void execute() throws IOException {
        try {
            getSeQuery().execute();
        } catch (SeException e) {
            throw new ArcSdeException(e);
        }
    }

    // //////////////////////////////////////////////////////////////////////
    // /////////////// METHODS WRAPPED FROM SeQuery /////////////////////
    // //////////////////////////////////////////////////////////////////////

    /**
     * Initializes a stream with a query using a selected set of columns and an SeSqlConstruct
     * object for the where clause. The where clause can?t contain any ORDER BY or GROUP BY clauses.
     * 
     * @throws IOException DOCUMENT ME!
     * @throws DataSourceException DOCUMENT ME!
     */
    // public void prepareQuery() throws IOException {
    // try {
    // getSeQuery().prepareQuery();
    // } catch (SeException e) {
    // throw new ArcSdeException(e);
    // }
    // }
    /**
     * Fetches an SeRow of data.
     * 
     * @return DOCUMENT ME!
     * @throws IOException (DataSourceException) if the fetching fails
     * @throws IllegalStateException if the query was already closed or {@link #execute()} hastn't
     *             been called yet
     */
    public SdeRow fetch() throws IOException, IllegalStateException {
        if (this.query == null) {
            throw new IllegalStateException("query closed or not yet executed");
        }

        final SeQuery seQuery = getSeQuery();
        try {
            SeRow row = seQuery.fetch();
            SdeRow currentRow = (row == null) ? null : new SdeRow(row, previousRowValues);
            previousRowValues = currentRow == null ? null : currentRow.getAll();
            return currentRow;
        } catch (SeException e) {
            close();
            String msg = "Error fetching row for " + this.schema.getTypeName() + "[";
            msg += "\nFilter: " + filters.sourceFilter;
            msg += "\n where clause sent: " + filters.sdeSqlConstruct.getWhere();
            msg += "\ngeometry filter:" + filters.geometryFilter;
            throw new ArcSdeException(msg, e);
        } catch (Exception e) {
            close();
            LOGGER.log(Level.SEVERE, "fetching row: " + e.getMessage(), e);
            throw new DataSourceException("fetching row: " + e.getMessage(), e);
        }
    }

    /**
     * Sets the spatial filters on the query using SE_OPTIMIZE as the policy for spatial index
     * search
     * 
     * @param filters a set of spatial constraints to filter upon
     * @throws IOException DOCUMENT ME!
     * @throws DataSourceException DOCUMENT ME!
     */
    public void setSpatialConstraints(SeFilter[] filters) throws IOException {
        try {
            getSeQuery().setSpatialConstraints(SeQuery.SE_OPTIMIZE, false, filters);
        } catch (SeException e) {
            throw new ArcSdeException(e);
        }
    }

    /**
     * DOCUMENT ME!
     * 
     * @return DOCUMENT ME!
     */
    // @Override
    public String toString() {
        return "Schema: " + this.schema.getTypeName() + ", query: " + this.query;
    }

    /**
     * DOCUMENT ME!
     * 
     * @author $author$
     * @version $Revision: 1.9 $
     */
    public static class FilterSet {
        /** DOCUMENT ME! */
        private SeQueryInfo definitionQuery;

        private PlainSelect layerSelectStatement;

        private FIDReader fidReader;

        /** DOCUMENT ME! */
        private final SeLayer sdeLayer;

        /** DOCUMENT ME! */
        private final Filter sourceFilter;

        /** DOCUMENT ME! */
        private Filter _sqlFilter;

        /** DOCUMENT ME! */
        private Filter geometryFilter;

        /** DOCUMENT ME! */
        private Filter unsupportedFilter;

        private FilterToSQLSDE _sqlEncoder;

        /**
         * Holds the ArcSDE Java API definition of the geometry related filters this datastore
         * implementation supports natively.
         */
        private SeFilter[] sdeSpatialFilters;

        /**
         * Holds the ArcSDE Java API definition of the <strong>non</strong> geometry related
         * filters this datastore implementation supports natively.
         */
        private SeSqlConstruct sdeSqlConstruct;

        private FeatureType featureType;

        /**
         * Creates a new FilterSet object.
         * 
         * @param sdeLayer DOCUMENT ME!
         * @param sourceFilter DOCUMENT ME!
         */
        public FilterSet(SeLayer sdeLayer,
                         Filter sourceFilter,
                         FeatureType ft,
                         SeQueryInfo definitionQuery,
                         PlainSelect layerSelectStatement,
                         FIDReader fidReader) {
            assert sdeLayer != null;
            assert sourceFilter != null;
            assert ft != null;

            this.sdeLayer = sdeLayer;
            this.sourceFilter = sourceFilter;
            this.featureType = ft;
            this.definitionQuery = definitionQuery;
            this.layerSelectStatement = layerSelectStatement;
            this.fidReader = fidReader;
            createGeotoolsFilters();
        }

        /**
         * Given the <code>Filter</code> passed to the constructor, unpacks it to three different
         * filters, one for the supported SQL based filter, another for the supported Geometry based
         * filter, and the last one for the unsupported filter. All of them can be retrieved from
         * its corresponding getter.
         */
        private void createGeotoolsFilters() {
            FilterToSQLSDE sqlEncoder = getSqlEncoder();

            PostPreProcessFilterSplittingVisitor unpacker = new PostPreProcessFilterSplittingVisitor(
                    sqlEncoder.getCapabilities(), featureType, null);
            sourceFilter.accept(unpacker, null);

            this._sqlFilter = unpacker.getFilterPre();

            if (LOGGER.isLoggable(Level.FINE) && _sqlFilter != null)
                LOGGER.fine("SQL portion of SDE Query: '" + _sqlFilter + "'");

            Filter remainingFilter = unpacker.getFilterPost();

            unpacker = new PostPreProcessFilterSplittingVisitor(GeometryEncoderSDE
                    .getCapabilities(), featureType, null);
            remainingFilter.accept(unpacker, null);

            this.geometryFilter = unpacker.getFilterPre();
            if (LOGGER.isLoggable(Level.FINE) && geometryFilter != null)
                LOGGER.fine("Spatial-Filter portion of SDE Query: '" + geometryFilter + "'");

            this.unsupportedFilter = unpacker.getFilterPost();
            if (LOGGER.isLoggable(Level.FINE) && unsupportedFilter != null)
                LOGGER.fine("Unsupported (and therefore ignored) portion of SDE Query: '"
                        + unsupportedFilter + "'");
        }

        /**
         * Returns an SeQueryInfo that can be used to retrieve a set of SeRows from an ArcSDE layer
         * or a layer with joins. The SeQueryInfo object lacks the set of column names to fetch. It
         * is the responsibility of the calling code to call setColumns(String []) on the returned
         * object to specify which properties to fetch.
         * 
         * @param unqualifiedPropertyNames non null, possibly empty, list of property names to fetch
         * @return
         * @throws SeException
         * @throws DataSourceException
         */
        public SeQueryInfo getQueryInfo(final String[] unqualifiedPropertyNames)
                throws SeException, DataSourceException {
            assert unqualifiedPropertyNames != null;
            String[] tables;
            String byClause = null;

            final SeSqlConstruct plainSqlConstruct = getSeSqlConstruct();

            String where = plainSqlConstruct.getWhere();

            if (definitionQuery == null) {
                tables = new String[] { this.sdeLayer.getQualifiedName() };
            } else {
                tables = definitionQuery.getConstruct().getTables();
                String joinWhere = definitionQuery.getConstruct().getWhere();
                if (where == null) {
                    where = joinWhere;
                } else {
                    where = joinWhere == null ? where : (joinWhere + " AND " + where);
                }
                try {
                    byClause = definitionQuery.getByClause();
                } catch (NullPointerException e) {
                    // no-op
                }
            }

            final SeQueryInfo qInfo = new SeQueryInfo();
            final SeSqlConstruct sqlConstruct = new SeSqlConstruct();
            sqlConstruct.setTables(tables);
            if (where != null && where.length() > 0) {
                sqlConstruct.setWhere(where);
            }

            final int queriedAttCount = unqualifiedPropertyNames.length;

            if (queriedAttCount > 0) {
                String[] sdeAttNames = new String[queriedAttCount];
                FilterToSQLSDE sqlEncoder = getSqlEncoder();

                for (int i = 0; i < queriedAttCount; i++) {
                    String attName = unqualifiedPropertyNames[i];
                    String coldef = sqlEncoder.getColumnDefinition(attName);
                    sdeAttNames[i] = coldef;
                }
                qInfo.setColumns(sdeAttNames);
            }

            qInfo.setConstruct(sqlConstruct);
            if (byClause != null) {
                qInfo.setByClause(byClause);
            }
            return qInfo;
        }

        /**
         * DOCUMENT ME!
         * 
         * @return the SeSqlConstruct corresponding to the given SeLayer and SQL based filter.
         *         Should never return null.
         * @throws DataSourceException if an error occurs encoding the sql filter to a SQL where
         *             clause, or creating the SeSqlConstruct for the given layer and where clause.
         */
        public SeSqlConstruct getSeSqlConstruct() throws DataSourceException {
            if (this.sdeSqlConstruct == null) {
                final String layerName;
                try {
                    layerName = this.sdeLayer.getQualifiedName();
                    this.sdeSqlConstruct = new SeSqlConstruct(layerName);
                } catch (SeException e) {
                    throw new ArcSdeException("Can't create SQL construct for "
                            + sdeLayer.getName(), e);
                }

                Filter sqlFilter = getSqlFilter();

                if (!Filter.INCLUDE.equals(sqlFilter)) {
                    String whereClause = null;
                    FilterToSQLSDE sqlEncoder = getSqlEncoder();

                    try {
                        whereClause = sqlEncoder.encodeToString(sqlFilter);
                    } catch (FilterToSQLException sqle) {
                        String message = "Geometry encoder error: " + sqle.getMessage();
                        throw new DataSourceException(message, sqle);
                    }
                    LOGGER.fine("ArcSDE where clause '" + whereClause + "'");

                    this.sdeSqlConstruct.setWhere(whereClause);
                }
            }

            return this.sdeSqlConstruct;
        }

        /**
         * Lazily creates the array of <code>SeShapeFilter</code> objects that map the
         * corresponding geometry related filters included in the original
         * <code>org.geotools.data.Query</code> passed to the constructor.
         * 
         * @return an array with the spatial filters to be applied to the SeQuery, or null if none.
         * @throws DataSourceException DOCUMENT ME!
         */
        public SeFilter[] getSpatialFilters() throws DataSourceException {
            if (this.sdeSpatialFilters == null) {
                GeometryEncoderSDE geometryEncoder = new GeometryEncoderSDE(this.sdeLayer,
                        featureType);

                try {
                    geometryEncoder.encode(getGeometryFilter());
                } catch (GeometryEncoderException e) {
                    throw new DataSourceException("Error parsing geometry filters: "
                            + e.getMessage(), e);
                }

                this.sdeSpatialFilters = geometryEncoder.getSpatialFilters();
            }

            return this.sdeSpatialFilters;
        }

        /**
         * DOCUMENT ME!
         * 
         * @return the subset, non geometry related, of the original filter this datastore
         *         implementation supports natively, or <code>Filter.INCLUDE</code> if the
         *         original Query does not contains non spatial filters that we can deal with at the
         *         ArcSDE Java API side.
         */
        public Filter getSqlFilter() {
            return (this._sqlFilter == null) ? Filter.INCLUDE : this._sqlFilter;
        }

        /**
         * DOCUMENT ME!
         * 
         * @return the geometry related subset of the original filter this datastore implementation
         *         supports natively, or <code>Filter.INCLUDE</code> if the original Query does
         *         not contains spatial filters that we can deal with at the ArcSDE Java API side.
         */
        public Filter getGeometryFilter() {
            return (this.geometryFilter == null) ? Filter.INCLUDE : this.geometryFilter;
        }

        /**
         * DOCUMENT ME!
         * 
         * @return the part of the original filter this datastore implementation does not supports
         *         natively, or <code>Filter.INCLUDE</code> if we support the whole Query filter.
         */
        public Filter getUnsupportedFilter() {
            return (this.unsupportedFilter == null) ? Filter.INCLUDE : this.unsupportedFilter;
        }

        private FilterToSQLSDE getSqlEncoder() {
            if (_sqlEncoder == null) {
                final String layerName;
                try {
                    layerName = sdeLayer.getQualifiedName();
                } catch (SeException e) {
                    throw (RuntimeException) new RuntimeException(
                            "error getting layer's qualified name").initCause(e);
                }
                String fidColumn = fidReader.getFidColumn();
                _sqlEncoder = new FilterToSQLSDE(layerName, fidColumn, featureType,
                        layerSelectStatement);
            }
            return _sqlEncoder;
        }
    }
}
